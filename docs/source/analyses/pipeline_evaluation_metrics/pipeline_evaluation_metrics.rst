RAPID Pipeline Evaluation
####################################################


Overview
************************************

Here we describe the procedures for evaluating the performance of the RAPID pipeline, 
downselecting algorithms (e.g., for difference imaging and source detection), and tuning 
parameters to optimize performance. This procedure is in development, and will be refined
as we continue to develop the pipeline and evaluate its performance on simulated data sets. 
In preparation for Roman launch, we will lay out specific plans and timelines to evaluate
the pipeline and tune parameters with in-flight data. These plans will be developed based on 
scheduled Roman observations as they become available.

Source injections 
**********************************************
Evalution of the RAPID pipeline performance relies on the injection of synthetic point sources. 
The currently implemented approach described below was developed for injection into OpenUniverse simulated images
of a nominal implementation of the HLTDS.

* Injections associated with detected sources/galaxies

    * Simple source detection and deblending is performed with **PhotUtils** on the science image with 
      a detection threshold of :math:`10\sigma` above the median background level. The bulk of these detections 
      will be galaxies in the field, but some may be stars or associated with the wings or diffraction spikes of
      bright stars. 

    * A random subset of the detected sources are selected for injections based on the desired number of injections 
      to perform per image, :math:`N_{\mathrm{inj}}`.

    * The location of each injection is randomly offset from the detected source centroid in both x and y using a 
      uniform distribution of half-width set to the detected source's estimated semi-major axis (``semimajor_sigma``
      measured by **PhotUtils**) multiplied by a scaling factor, ``size_factor``.

    * The flux in image counts (electrons) of each injection is drawn from a uniform distrubtion of magnitdues between 
      21 and 28 AB mag, using the appropiate zeropoint for the image filter, Roman SCA, and exposure time. 
    
    * A PSF for each injection is computed using the **Roman I-Sim** tool **romanisim.image.make_one_psf** for the given filter, SCA,
      and detector position, based on the **galsim.roman** module, to emulate the PSFs used for the original OpenUniverse 
      Roman simulations. Chromatic effects are currently ignored. 

    * The injection is added to the science image with **romanisim.image.add_objects_to_image** at the specified location, 
      with the appropriate PSF and flux and including poisson noise. 

Additional schemes for source injections currently under consideration for implementation include:

* Injections at random positions in the image or a pre-defined grid, independent of detected sources. This scheme would be 
  useful to evaluate the performance of the pipeline for hostless transients, or in crowded fields (e.g., for the GBTDS and
  associated simulations). 
* Injections in time-series images of a given field at specified sky locations with pre-defined light curves. This could also 
  include the injection of a stellar counterparts in the images used to generate reference mosaics to evaluate the performance 
  of the pipeline for variable stars.

Detection Catalog filtering
**********************************************************

Raw detection catalogs generated by the RAPID pipeline will contain a significant number of spurious detections arising from
imperfect image subtraction resulting in significant residuals from static galaxies and stellar sources, noise fluctuations, 
and detector artifacts such as unflagged hot-pixels or cosmic-ray hits. A series of filtering steps, in order of 
increasing computational expense, are performed to clean the raw catalogs and provide metrics/features as inputs to machine-learning 
based real-bogus (RB) classifier. This procedure adapted from that developed for the `ZTF Science Data System`_, and is under active
development. 

.. _ZTF Science Data System: https://irsa.ipac.caltech.edu/data/ZTF/docs/ztf_explanatory_supplement.pdf

1. Catalog-level filtering based on measurements performed during source detection (e.g., by **SExtractor** or **Photutils DAOStarFinder**):
 
    a. ``mindedge`` :math:`\gt` ``diffimedgetol``: Minimum distance from any image edge in pixels. 
    
    b. ``snrap3pix`` :math:`\geq` ``snrthres``: Signal-to-noise ratio (S/N) measured in a 3-pix diameter aperature at the candidate position 
       in the difference image and corresponding uncertainty map. A initial threshold of ``snrthres`` :math:`=5` is adopted. 

    c. ``elong`` :math: `\leg` ``elongthres``: Source elongation (ratio A/B of semi-major to semi-minor axis). 

    d. (``apfluxratio`` :math:`\geq` ``apfluxratiothreslow``) and (``apfluxratio`` :math:`\leq` ``apfluxratiothreshigh``): Ratio of flux 
       measured in a 3-pixel diameter aperture to that measured in a 6-pixel diameter aperture. 
    
    .. note::
       These filtering steps are based on measurements available in SExtractor catalogs. If **Photutils DAOStarFinder** or another detection 
       method is employed, analagous measurements will be used. Additional metrics like ``sharpness`` and ``roundness`` estimated by DAOStarFinder 
       could also be employed. 

2. Pixel-level metrics based on a 5x5 cutout of the difference image centered on each candidate:

    a. ``nneg`` :math:`\leq` ``nnegthres``: Number of negative-valued pixels in the cutout.

    b. ``nbad`` :math:`\leq` ``nbadthres``: Number of pixels flagged as bad in the cutout.

    .. note::
       Currently "bad" pixels are only those masked as NaN in the difference image due to lack of coverage in the reference mosaic. 

    c. ``sumrat`` :math:`\leq` ``sumratthres``: A 3x3 median filter is applied to the cutout, with kernel trucation at the cutout edges (i.e., 
       unavailable or NaN pixel values are simply ignored). ``sumrat`` is defined as the ratio of the sum of pixel values in median filtered cutout
       to the sum of their absolute values. For Gaussian-distributed noise, a value bewteen :math:`-0.25 \lt` ``sumrat`` :math:`\lt 0.25` is expected, 
       while the value approaches 1 for real signal. 

3. PSF-fitting photometry quality cuts:

    a. :math:`0 \lt` ``chipsf`` :math:`\lt` ``chipsfthres``: The reduced chi-squared of the PSF fit.

    b. :math:`|` ``magap3pix`` :math:`-` ``magpsf`` :math:`| \lt` ``magdiffthres``: Difference between the magnitude measured in a 3-pixel 
       diameter aperture (with appropriate aperture correction), and the PSF-fit magnitude.

4. Machine-learning based real-bogus (RB) classification using all relevant features/metrics described above, along with available metadata (e.g., 
   positional assoication with stars or galaxies in the reference image).

Figure of Merit
**********************************************
We define a figure of merit (FOM) to evaluate the performance of the RAPID pipeline, to enable 
down-selection of algorithms (e.g., ZOGY or SFFT for image subtraction), and to guide tuning of 
parameters and thresholds. In broad strokes, we define the FOM as an effective limiting magnitude 
for a specified data set composed of multiple terms. These are, in approximate order of general
importance/weight: (1) the average magnitdue corresponding to the S/N threshold that achieves an 
accepatable false-positive rate per image, :math:`m_{\mathrm{th}}`, (2) the magnitude at which 80% of 
injected sources are successfully recovered, :math:`m_{80}`, (2) the magnitude at which 20% of 
injected sources are successfully recovered, :math:`m_{20}`, (4) the :math:`5\sigma` point-source 
limiting magnitude on blank sky, :math:`m_{5\sigma}` in the difference images, and (5) the magnitude 
at which injected fluxes are recovered with 10% precision in PSF-fitting photometry, :math:`m_{\mathrm{ph}10}`.  

Each term is calculated as a weighted sum over the filters, :math:`f`, present in the test data set, 
and the final FOM is then a weighted sum of each of these terms:

.. math::
   \mathrm{FOM} = \left(w_{\mathrm{th}} \frac{\sum_{f} w_{\mathrm{th},f} m_{\mathrm{th},f}}{\sum_{f} w_{\mathrm{th},f}}
   + w_{80} \frac{\sum_{f} w_{80,f} m_{80,f}}{\sum_{f} w_{80,f}}
   + w_{20} \frac{\sum_{f} w_{20,f} m_{20,f}}{\sum_{f} w_{20,f}}
   + w_{5\sigma} \frac{\sum_{f} w_{5\sigma,f} m_{5\sigma,f}}{\sum_{f} w_{5\sigma,f}}
   + w_{\mathrm{ph10}} \frac{\sum_{f} w_{\mathrm{ph10},f} m_{\mathrm{ph10},f}}{\sum_{f} w_{\mathrm{ph10},f}}\right) \\\\
   / (w_{\mathrm{th}} + w_{80} + w_{20} + w_{5\sigma} + w_{\mathrm{ph10}}).

The weights, :math:`w`, can be adjusted to emphasize different aspects of the performance of the pipeline 
or to prioritize performance in certain filters. Additionally, the calcuation of each term can 
be further broken out by characteristics of the injected sources (e.g, transients on top of bright hosts, 
hostless events, nuclear tranisents, or variables with stellar counterparts) and weighted accordingly. In 
general, the RAPID pipeline needs to perform well across all Roman surveys, filters, and for a broad range
of transients and variables. 


Evaluation Procedure
**********************************************
Here we describe the steps to evaluate the pipeline and calculate each term of the FOM in more detail.

1. Define setup for evaluation and run pipeline:    

    a. Define data set and injection parameters. Prior to launch, the data set could be, e.g., one test runs of the pipeline
       using OpenUniverse HLTDS simulations or a RimTimSim GBTDS set (see :ref:`testing`). Post-launch, we will define specific subsets of 
       the survey data to use for evaluation with fake-source injection, e.g., a set fields from the HLTDS over a specific 
       time period. The injection parameters include the number of injections per image, their magnitude distribution, and the 
       specifications for the method used to assign their positions (i.e., regular grid, random positions, randomized offsets from 
       detected galaxies, on top of stars, etc.).
    
    b. Specify any pipeline modules, steps, or settings to be comparitively tested. For example, this may be the image subtraction 
       algorithm (ZOGY vs SFFT vs Naive), the detection method (SExtractor vs Photutils DAOStarFinder), or settings for a specific algorthm 
       (e.g., SEXtractor detection thresholds). 
    
    c. Specify all axes of evalution, and their desired weights. At minimum, this includes the filters present in the data set. It may
       also include properties of the injected sources (e.g., separation from host galaxy core, transients vs. variables).
    
    d. Run the pipeline on the test data set with the specified injections and settings to be tested. 

2. Following the completion of image subtraction and the generation of raw detection catalogs, the catalogs are filtered using the set of pre-defined 
   thresholds to remove the bulk of suprious candidates, as described above in . PSF-fitting photometry is then performed for all candidates
   passing these criteria using the relevant difference images, corresponding uncertainty maps, and the unit-normalized PSF models computed for the
   difference images. Candidates are then filtered again based on the results of PSF-fitting. 

3. Each surviving transient candidate is positionally cross-matched to the nearest source in the reference image. For simulated OpenUniverse data, 
   this can be done by cross-matching to galaxies brigher than ``galmatchthres`` from the simulation truth-catalogs. For real data, we will 
   cross-match to the reference image source catalogs generated by the pipeline, inluduing any metadata that can be used to separate stars and galaxies. 

4. Additional vetting of candidates is performed using machine-learning (ML) based real-bogus (RB) classification using all relevant features
   and metadata described above. 

5. Candidates are cross-matched to the injected source catalogs (or OpenUniverse truth catalog transients) using a matching radius 
   of ``injmatchrad``. Candidates passing all filter criteria and matched an injected source are considered successfully recovered 
   true positives (TPs). Candidates passing all filter criteria, but not matched to an injected source are considered false positives (FPs). 

6. All terms of the FOM are calculated for each filter and sub-groups of injections/detetions (e.g., injections/candidates separated from the nearest 
   galaxy from step 3 by :math:`\gt 1.5 \times` ``injmatchrad``): 

    a. :math:`m_{\mathrm{th}}`: FP candidates are grouped by :math:`m_{3\mathrm{pix}}` in :math:`\Delta m = 0.2` bins. The number 
       of FP candidates at or brighter than each magnitude bin, :math:`N_{\mathrm{FP}\lt m}`, is calculated. :math:`m_{\mathrm{th}}` is computed as the 
       magnitude where a linear interoplation of :math:`N_{\mathrm{FP}\lt m}` crosses the defined FP rate tolerance, ``fpratetol``. The S/N corresponding
       to :math:`m_{\mathrm{th}}` is similarly computed via linear interpolation of the average S/N of FP candidates in each bin, and defines a threshold 
       ``snrfpthres`` to ensure consistency with ``fpratetol``. 

    b. :math:`m_{80}` and :math:`m_{20}`: The recovery completess (fraction of injected sources in the sub-group of interest successfully recovered) 
       is computed in :math:`\Delta m = 0.5` bins of injected magnitude for all TP candidates passing :math:`SNR \geq` ``snrfpthres``. 
       The calculations accounts for the number of injected sources that lacked coverage in the reference image or fell within ``diffimedgetol`` 
       of any image boundary. `m_{80}` and :math:`m_{20}` are computed via linear interpolation of the completness curve at 80% and 20% completeness, 
       respectively.

    c. :math:`m_{5\sigma}`: For each difference image, :math:`6\sigma`-clipped standard deviation of all pixel values is calculated as a 
       estimate of the background noise, :math:`\sigma_{\mathrm{diffbkg}}`. This value can be compared to the sigma-clipped average of the 
       corresponding difference uncertainty map to ensure uncertainty maps are reasonable. The :math:`5\sigma` point-source limiting flux is 
       then calculated as :math:`5 \sqrt{N_p} \sigma_{\mathrm{diffbkg}}`, where :math:`N_p` is the number of `noise pixels`_ of the 
       unit-normalized PSF model for the difference image, and converted to a limiting magnitude :math:`m_{5\sigma}` using with the appropriate 
       AB magnitude zeropoint.  

    d. :math:`m_{\mathrm{ph}10}`: The fractional error between the recovered PSF-fit flux and the injected flux is calcualated for all TP candidates 
       as :math:`(f_{\mathrm{PSF}} - f_{\mathrm{inj}})/f_{\mathrm{inj}}` and grouped in :math:`\Delta m = 0.5` bins of injected magnitude. 
       :math:`m_{\mathrm{ph}10}` is computed via linear interpolation of the fractional errors for each bin for 10% precision. 
       
       .. note::
          This does not account for systematic biases in the recovered fluxes, but is only an estimate of the statistical precision.

7. The final FOM is calculated using the specified weights for each term and filter/sub-group as described above. The version of the pipeline (with choices of subtraction algorithm, 
   detection method, or specific parameter settings) that maximizes the FOM is judged to be better performing.

.. _noise pixels: https://web.ipac.caltech.edu/staff/fmasci/home/mystats/noisepix_specs.pdf
